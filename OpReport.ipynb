{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "  \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "  with torch.no_grad():\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "      correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "      res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "class ProgressMeter(object):\n",
    "  def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "    self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "    self.meters = meters\n",
    "    self.prefix = prefix\n",
    "\n",
    "  def display(self, batch):\n",
    "    entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "    entries += [str(meter) for meter in self.meters]\n",
    "    print('\\t'.join(entries))\n",
    "\n",
    "  def _get_batch_fmtstr(self, num_batches):\n",
    "    num_digits = len(str(num_batches // 1))\n",
    "    fmt = '{:' + str(num_digits) + 'd}'\n",
    "    return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "class AverageMeter(object):\n",
    "  \"\"\"Computes and stores the average and current value\"\"\"\n",
    "  def __init__(self, name, fmt=':f'):\n",
    "    self.name = name\n",
    "    self.fmt = fmt\n",
    "    self.reset()\n",
    "    self.epoch_sum = 0\n",
    "    self.epoch_count = 0\n",
    "    self.epoch_avg = 0\n",
    "\n",
    "  def reset(self):\n",
    "#     self.val = 0\n",
    "    self.avg = 0\n",
    "    self.sum = 0\n",
    "    self.count = 0\n",
    "\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count\n",
    "    self.epoch_sum += val * n\n",
    "    self.epoch_count += n\n",
    "    self.epoch_avg = self.epoch_sum / self.epoch_count\n",
    "    \n",
    "  def __str__(self):\n",
    "    fmtstr = '{name} {avg' + self.fmt + '} ({epoch_avg' + self.fmt + '})'\n",
    "    return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /workspace/FixRes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imnet_finetune.resnext_wsl import *\n",
    "\n",
    "model = resnext101_32x48d_wsl(progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "## Settings\n",
    "batch_size = 2\n",
    "\n",
    "###################################################\n",
    "## Load Data\n",
    "# dataloaders = {}\n",
    "# dataloaders['train'], dataloaders['val'] = get_train_val_loaders('./data', batch_size, val_ratio)\n",
    "# trainloader, _ =  get_train_val_loaders('./data', batch_size, val_ratio)\n",
    "\n",
    "# classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "from imnet_finetune.transforms import get_transforms\n",
    "transformation = get_transforms(input_size=320,test_size=320, kind='full', crop=True, need=('train', 'val'), backbone=None)\n",
    "trainset = torchvision.datasets.ImageFolder('/workspace/data/train', transform=transformation['val'])\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, num_workers=2)\n",
    "print(trainset)\n",
    "\n",
    "###################################################\n",
    "## Load Model\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define/load model\n",
    "# num_ftrs = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_ftrs, 10)\n",
    "# Send model to GPU\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function (criterion) and optimizer and LR scheduler\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "# NOTE: define optimizer after sending model to GPU. May lead to error otherwise.\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) \n",
    "#   lrscheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to train mode\n",
    "losses = AverageMeter('Loss', ':.4e')\n",
    "top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "\n",
    "model.train()\n",
    "\n",
    "# batch times\n",
    "# batchTimes = []\n",
    "metrics = []\n",
    "\n",
    "trainiter = iter(trainloader)\n",
    "# specify which batch you want to profile\n",
    "batches = 1\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.autograd.profiler.profile(enabled=True, use_cuda=True, record_shapes=True) as prof:\n",
    "    for i in range(batches):\n",
    "        images, target = trainiter.next()\n",
    "        # time\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        images = images.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "      # compute gradients and do kprop \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # time\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        print(\"Time: \", end-start)\n",
    "        # measure accuracy and record loss\n",
    "#         _, predicted = torch.max(output.data, 1)\n",
    "#         total += target.size(0)\n",
    "#         correct += (predicted == target).sum().item()\n",
    "#         print(' * TRAIN: Acc@1 {:.3f}'.format(correct/total))\n",
    "# #         metrics.append(' * TRAIN: Acc@1 {:.3f}'.format(correct/total))\n",
    "#         correct = total = 0\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "        print(' * TRAIN: Acc@1 {top1.epoch_avg:.3f} Acc@5 {top5.epoch_avg:.3f}'.format(top1=top1, top5=top5))\n",
    "    \n",
    "# print(prof)\n",
    "# print(batchTimes)\n",
    "print('\\n'.join(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### run the above cell twice since the profiler output of the first and consequent runs are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to do this otherwise children are not populated (lazy call)\n",
    "prof.table(row_limit=1)\n",
    "children = []\n",
    "events = {}\n",
    "for evt in prof.function_events:\n",
    "    children.extend([child.id for child in evt.cpu_children])\n",
    "    events[evt.id] = evt\n",
    "children = set(children)\n",
    "print(len(children))\n",
    "print(len(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainevts = [evt for evt in prof.function_events if evt.id not in children]\n",
    "# print([evt.name for evt in mainevts if evt.name not in ['detach_', 'set_', 'zero_']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pysum = 0\n",
    "for evt in prof.function_events:\n",
    "    pysum += evt.cuda_time_total\n",
    "mysum = 0\n",
    "for evt in mainevts:\n",
    "    mysum += evt.cuda_time_total\n",
    "print(pysum, mysum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate running time from the start of first kernel to end of last kernel\n",
    "mint = mainevts[0].kernels[0].interval.start\n",
    "maxt = mainevts[0].kernels[0].interval.end\n",
    "for evt in mainevts:\n",
    "    mint = min(mint, evt.kernels[0].interval.start)\n",
    "    maxt = max(maxt, evt.kernels[0].interval.end)\n",
    "print(maxt-mint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def isCudnnOperation(e):\n",
    "    if \" \" in e.name:\n",
    "        return True\n",
    "    for child in e.cpu_children:\n",
    "        iscudnnchild = isCudnnOperation(child)\n",
    "        if iscudnnchild:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "mainevts_cudatime = []\n",
    "for e in mainevts:\n",
    "    item = [e.name, e.kernels[0].interval.start, e.kernels[0].interval.elapsed_us(), e.input_shapes, not isCudnnOperation(e)]\n",
    "    mainevts_cudatime.append(item)\n",
    "# print(len(mainevts_cudatime))\n",
    "df = pd.DataFrame(mainevts_cudatime, columns=['name','cudaStart', 'cudaDuration', 'inputShapes', 'isNative'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops = df.groupby(['name'])['cudaDuration'].sum().reset_index(name ='totalCudaTime')\n",
    "ops.sort_values('totalCudaTime', inplace=True, ascending=False)\n",
    "\n",
    "total_cuda_time = ops['totalCudaTime'].sum()\n",
    "# print(total_cuda_time)\n",
    "\n",
    "ops['%ageCudaTime'] = ops.apply(lambda row: (row.totalCudaTime*100)/total_cuda_time, axis=1)\n",
    "display(ops.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ops.to_csv('/workspace/DeepLearningMisc/resnext101_32x8d_b28-ops.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df.tail(50))\n",
    "toIndices = df.index[df['name'] == \"to\"].tolist()\n",
    "print(toIndices)\n",
    "\n",
    "accComputeStartIndex = df.index[df['name'].str.contains(\"topk\")].tolist()\n",
    "print(accComputeStartIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert toIndices[2]+1 == toIndices[3], \"check starting index\"\n",
    "actdf = df.loc[toIndices[2]:(accComputeStartIndex[0]-1)]\n",
    "actdf.reset_index(inplace=True, drop=True)\n",
    "display(actdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actdf.to_csv('/workspace/DeepLearningMisc/resnext101_32x48d_b2-pytorchtrace.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = actdf.copy(deep=True)\n",
    "display(tmp.head())\n",
    "\n",
    "nativeOps = tmp.index[tmp['isNative'] == True].tolist()\n",
    "print(len(nativeOps), len(actdf))\n",
    "\n",
    "gaps = {}\n",
    "for i in range(len(nativeOps)-1):\n",
    "    f = nativeOps[i]\n",
    "    s = nativeOps[i+1]\n",
    "    if s-f-1 > 1:\n",
    "        gaps[(f,s)] = s-f-1\n",
    "print(gaps)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prof.table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
