{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# file = '/home/ubuntu/MLPerf_ROCm/mlperf_training/v0p6/rnn_translator/pytorch/rnn_translator-nvtx.csv'\n",
    "file = '/home/ubuntu/DeepLearningMisc/microbench/resnext101_32x8d-nvtx-1042s877m.csv'\n",
    "\n",
    "initdf = pd.read_csv(file, skiprows=5,\n",
    "                 names=['start','duration','gridX','gridY','gridZ','blockX','blockY','blockZ',\n",
    "                        'registersPerThread','staticSMem','dynamicSMem','size','throughput',\n",
    "                        'srcMemType','dstMemType','device','context','stream','name','corrid'])\n",
    "# staticSMem - KB, dynamicSMem - KB, size - MB, throughput - GB/s\n",
    "# print(initdf.shape)\n",
    "# display(initdf.tail())\n",
    "initdf.dropna(subset=['name'], inplace=True)\n",
    "initdf.drop(['gridX','gridY','gridZ','blockX','blockY','blockZ','srcMemType','dstMemType','device'], axis=1, inplace=True)\n",
    "\n",
    "# demangling the name\n",
    "initdf['name'] = initdf['name'].apply(torch._C._demangle)\n",
    "\n",
    "startprof = initdf.index[initdf['name'].str.contains(\"\\[Marker\\] __start_profile\")].tolist()\n",
    "assert len(startprof) == 1\n",
    "stopprof = initdf.index[initdf['name'].str.contains(\"\\[Marker\\] __stop_profile\")].tolist()\n",
    "assert len(stopprof) == 1\n",
    "initdf = initdf.loc[startprof[0]:stopprof[0], :] \n",
    "# print(initdf.shape)\n",
    "\n",
    "df = initdf.dropna(subset=['registersPerThread','staticSMem','dynamicSMem','size','throughput'], how='all')\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contains markers and Cuda Launch Kernels\n",
    "markers = initdf[(initdf['name'].str.contains(\"\\[Range start\\]\")) | (initdf['name'].str.contains(\"\\[Range end\\]\")) | (initdf['name'].str.contains(\"Marker\")) | (initdf['name'] == \"cudaLaunchKernel\") | (initdf['name'].str.contains(\"cudaMemcpy\"))]\n",
    "print(markers.shape)\n",
    "display(markers.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Marker = namedtuple('Marker', 'index name depth')\n",
    "# Op = namedtuple('Op', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = []\n",
    "opsToCorrid = {}  # marker operation index -> cuda launch kernel correlation id\n",
    "\n",
    "# # Helper dicts (not essential)\n",
    "# opsIndexToName = {}  # marker operation index -> pytorch operation name\n",
    "\n",
    "for index, row in markers.iloc[1:-1].iterrows():\n",
    "    name = row['name']\n",
    "    if \"pin_memory\" in name:\n",
    "        continue\n",
    "\n",
    "    if \"[Range start]\" in name:\n",
    "        pat = re.compile(r'\\[Range start\\] (?P<name>[a-zA-Z0-9_:]*), (seq = \\d+)?(, )?(?P<size>sizes = \\[[\\[\\],\\d ]*\\])? \\(Domain: \\<unnamed\\>\\)')\n",
    "        details = pat.match(name)\n",
    "        if not details:\n",
    "            print(\" *** Error handling regex name matching:{}\".format(name))\n",
    "            continue\n",
    "        mname = details.group('name')\n",
    "        if details.group('size'):\n",
    "            mname = mname + \", \" + details.group('size')\n",
    "        marker = Marker(index, mname, len(stack))\n",
    "#         print(\"pushing into stack: {}, {}\".format(index, row['name']))\n",
    "        stack.append(marker)\n",
    "        opsToCorrid[marker] = []\n",
    "        \n",
    "    elif \"[Range end]\" in name:\n",
    "        marker = stack.pop()\n",
    "        top = markers.loc[marker.index, 'name']\n",
    "        match = top.replace(\"start\",\"end\")\n",
    "        tmpst = []\n",
    "        while(len(stack) and (match != name)):\n",
    "            tmpst.append(marker)\n",
    "            marker = stack.pop()\n",
    "            match = markers.loc[marker.index, 'name'].replace(\"start\", \"end\")\n",
    "        \n",
    "        if len(tmpst):\n",
    "            print(\" *** does not match; this shouldn't happen ideally: {}\".format(index))\n",
    "        \n",
    "        while(len(tmpst)):\n",
    "            m = tmpst.pop()\n",
    "            stack.append(m)\n",
    "\n",
    "#         if match != name:\n",
    "# #             print(\"Popped from stack: {}\".format(top))\n",
    "# #         else:\n",
    "#             print(\" *** does not match; this shouldn't happen ideally: {}\".format(index))\n",
    "#             stack.append(marker)\n",
    "        \n",
    "    elif (name == \"cudaLaunchKernel\") or (\"cudaMemcpy\" in name):\n",
    "#         print(\"cuda launch kernel: {}\".format(row['corrid']))\n",
    "        for marker in stack:\n",
    "            opsToCorrid[marker].append(row['corrid'])\n",
    "        if len(stack) == 0:\n",
    "            print(\" *** Kernel with corrid: {} doesn't lie between any markers\".format(row['corrid']))\n",
    "    else:\n",
    "        print(\" *** wrong option\")\n",
    "\n",
    "print(len(opsToCorrid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delkeys = []\n",
    "for i, corrids in opsToCorrid.items():\n",
    "    if len(corrids) == 0:\n",
    "        delkeys.append(i)\n",
    "\n",
    "for key in delkeys:\n",
    "    opsToCorrid.pop(key, None)\n",
    "    \n",
    "print(len(opsToCorrid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allCorrids = []\n",
    "for i, corrids in opsToCorrid.items():\n",
    "    allCorrids.extend(corrids)\n",
    "print(len(allCorrids))\n",
    "\n",
    "allCorrids = set(allCorrids)\n",
    "print(len(allCorrids))\n",
    "\n",
    "# print(opsToCorrid[7096])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corridToKernelIndex = {}  # cuda launch kernel correlation id -> index of kernel with corresponding correlation id\n",
    "# Helper dicts (not essential)\n",
    "kernelIndexToRow = {}\n",
    "\n",
    "for corrid in allCorrids:\n",
    "    rowIndex = df.index[df['corrid'] == int(corrid)].tolist()\n",
    "    assert len(rowIndex) == 1, \"multiple kernels with same corrid\"\n",
    "    corridToKernelIndex[corrid] = rowIndex[0]\n",
    "    \n",
    "    # can remove\n",
    "    kernelIndexToRow[rowIndex[0]] = df.loc[rowIndex[0]]\n",
    "\n",
    "print(len(corridToKernelIndex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opsToKernelIndex = {}  # marker operation index -> index of corresponding kernel call\n",
    "for opIndex, corrids in opsToCorrid.items():\n",
    "    opsToKernelIndex[opIndex] = []\n",
    "    for corrid in corrids:\n",
    "        opsToKernelIndex[opIndex].append(corridToKernelIndex[corrid])\n",
    "\n",
    "print(len(opsToKernelIndex))\n",
    "# print(opsToKernelIndex)  # add 6 to indices to get line numbers in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappingdf = pd.DataFrame(list([marker.name, \n",
    "                               marker.depth, \n",
    "                               [kernelIndexToRow[kid]['name']+\"[\"+str(kernelIndexToRow[kid]['stream'])+\"]\" for kid in kids], \n",
    "                               len(kids),\n",
    "                               kernelIndexToRow[kids[0]]['start'],\n",
    "                               sum([kernelIndexToRow[kid]['duration'] for kid in sorted(kids)])\n",
    "                              ] for marker,kids in opsToKernelIndex.items()), \n",
    "                         columns=['pyName', 'depth', 'kernelNames', 'numKernels', 'startTime', 'sumKernelDuration'])\n",
    "mappingdf['startTime'] = mappingdf['startTime'].astype(float)\n",
    "print(mappingdf.shape)\n",
    "display(mappingdf.head(50))\n",
    "# mappingdf.to_csv('/home/ubuntu/DeepLearningMisc/microbench/resnet101_32x8d-mapping.csv')\n",
    "# mappingdf.to_csv('/home/ubuntu/logs/rnn_translator-mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topdf = mappingdf[mappingdf['depth']==0]\n",
    "topdf.drop(['depth'], axis=1, inplace=True)\n",
    "print(topdf.shape)\n",
    "display(topdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topdf['duration'] = topdf['startTime'].shift(-1, axis=0) - topdf['startTime']\n",
    "print(topdf.shape)\n",
    "display(topdf.head(50))\n",
    "# topdf.to_csv('/home/ubuntu/logs/ncf-mapping-top.csv')\n",
    "# topdf.to_csv('/home/ubuntu/logs/rnn_translator-mapping-top.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toOps = topdf[topdf['pyName'].str.contains(\"to,\")].index.tolist()\n",
    "toOps = topdf[topdf['pyName'].str.contains(\"conv2d, sizes = \\[\\[32, 3, 224, 224\\], \\[64, 3, 7, 7\\], \\[\\]\")].index.tolist()\n",
    "\n",
    "# should be sets of 3 consecutive indices\n",
    "print(toOps)\n",
    "#ignore first batch\n",
    "# batchStartIndices = [toOps[i] for i in range(len(toOps)) if i%4 == 0]\n",
    "batchStartIndices = toOps\n",
    "print(batchStartIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = topdf.loc[batchStartIndices[0]:batchStartIndices[1]-1]\n",
    "b1.reset_index(inplace=True, drop=True)\n",
    "# display(b1)\n",
    "b2 = topdf.loc[batchStartIndices[1]:batchStartIndices[2]-1]\n",
    "b2.reset_index(inplace=True, drop=True)\n",
    "\n",
    "b3 = topdf.loc[batchStartIndices[2]:batchStartIndices[3]-1]\n",
    "b3.reset_index(inplace=True, drop=True)\n",
    "\n",
    "b4 = topdf.loc[batchStartIndices[3]:batchStartIndices[4]-1]\n",
    "b4.reset_index(inplace=True, drop=True)\n",
    "\n",
    "b5 = topdf.loc[batchStartIndices[4]:]\n",
    "b5.reset_index(inplace=True, drop=True)\n",
    "display(b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b1.shape, b2.shape, b3.shape, b4.shape, b5.shape)\n",
    "# all must be equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivotBatch = pd.concat([b1,b2,b3,b4,b5], axis=1, keys=['b1','b2','b3','b4','b5'])\n",
    "print(pivotBatch.shape)\n",
    "display(pivotBatch[[('b1','pyName'), ('b2','pyName'), ('b3','pyName'), ('b4','pyName'), ('b5','pyName')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = pivotBatch[[('b1','sumKernelDuration'), ('b2','sumKernelDuration'), ('b3','sumKernelDuration'), ('b4','sumKernelDuration'), ('b5','sumKernelDuration')]]\n",
    "pivotBatch['diffDuration'] = ref.max(axis=1) - ref.min(axis=1)\n",
    "# display(pivotBatch)\n",
    "# pivotBatch.sort_values('diffDuration', ascending=False, inplace=True)\n",
    "pivotBatch[[('b1', 'pyName'), ('b1','kernelNames'), ('b1', 'numKernels'), ('b1','sumKernelDuration'), ('b2','sumKernelDuration'), ('b3','sumKernelDuration'), ('b4','sumKernelDuration'), ('b5','sumKernelDuration'), ('diffDuration','')]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ref.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fwd pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#consider b4 batch\n",
    "fwd_end = b4.index[b4['pyName'].str.contains(\"log_softmax\")].tolist()\n",
    "assert len(fwd_end) == 1, \"ERROR\"\n",
    "fwd = b4.loc[:fwd_end[0]]\n",
    "display(fwd)\n",
    "fwd.to_csv('/home/ubuntu/logs/resnext101_32x8d-fwdall-nv-1042s877m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd = fwd[fwd['pyName']!=\"add_, sizes = [[], [], []]\"]\n",
    "fwd.reset_index(inplace=True, drop=True)\n",
    "display(fwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd[fwd['pyName'].str.contains(\"batch_norm\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = fwd[~(fwd['pyName'].str.startswith(\"conv2d\") | fwd['pyName'].str.startswith(\"batch_norm\"))]\n",
    "# display(tmp[tmp['numKernels'] > 1])\n",
    "display(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'duration':'sumDuration'}, inplace=True)\n",
    "df['start'] = pd.to_numeric(df['start'])\n",
    "df['duration'] = df['start'].shift(-1, axis=0) - df['start']\n",
    "df['start'] = df['start'].apply(str)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df[(df['name'] == '[CUDA memcpy HtoD]') & (df['size'] == 0.015625)].index.tolist()\n",
    "print(tmp)\n",
    "batchStartIndices = [tmp[i] for i in range(len(tmp)) if i%2==0]\n",
    "print(batchStartIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemmdf = df[df['name'].str.contains('sgemm')]\n",
    "gemmdf.drop(['registersPerThread','staticSMem','dynamicSMem','size','throughput','context','stream','corrid'], axis=1, inplace=True)\n",
    "b2gemm = gemmdf.loc[batchStartIndices[1]:batchStartIndices[2]]\n",
    "b2gemm.reset_index(inplace=True, drop=True)\n",
    "b3gemm = gemmdf.loc[batchStartIndices[2]:batchStartIndices[3]]\n",
    "b3gemm.reset_index(inplace=True, drop=True)\n",
    "b4gemm = gemmdf.loc[batchStartIndices[3]:batchStartIndices[4]]\n",
    "b4gemm.reset_index(inplace=True, drop=True)\n",
    "b5gemm = gemmdf.loc[batchStartIndices[4]:batchStartIndices[5]]\n",
    "b5gemm.reset_index(inplace=True, drop=True)\n",
    "b6gemm = gemmdf.loc[batchStartIndices[5]:]\n",
    "b6gemm.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(b2gemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = pd.concat([b2gemm, b3gemm, b4gemm, b5gemm, b6gemm], axis=1, keys=['b2','b3','b4','b5','b6'])\n",
    "\n",
    "pivot['avgSumDuration'] = pivot[[('b2','sumDuration'),('b3','sumDuration'),('b4','sumDuration'),('b5','sumDuration'),('b6','sumDuration')]].mean(axis=1)\n",
    "pivot['avgDuration'] = pivot[[('b2', 'duration'),('b3', 'duration'),('b4', 'duration'),('b5', 'duration'),('b6', 'duration')]].mean(axis=1)\n",
    "display(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pivot[('avgDuration','')].tolist():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2gemm['sumDuration'].quantile([0.1,0.25,0.5,0.75,0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN TRANSLATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['duration'], axis=1, inplace=True)\n",
    "df.rename(columns={'kernelDuration':'duration'}, inplace=True)\n",
    "df.rename(columns={'duration':'kernelDuration'}, inplace=True)\n",
    "df['start'] = pd.to_numeric(df['start'])\n",
    "df['duration'] = df['start'].shift(-1, axis=0) - df['start']\n",
    "df['start'] = df['start'].apply(str)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['name'].str.contains('indexSelectLargeIndex')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['name'] == '[CUDA memcpy HtoD]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
